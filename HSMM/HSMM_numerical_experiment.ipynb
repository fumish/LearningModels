{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSMMの性能比較の数値実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from IPython.core.display import display, Markdown, Latex\n",
    "import numpy as np\n",
    "from scipy.special import gammaln, psi\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm, t, cauchy, laplace, gumbel_r, gamma, skewnorm, pareto, multivariate_normal\n",
    "from typing import Callable\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "from learning import HyperbolicSecantMixtureVB, GaussianMixtureModelVB\n",
    "from util import GaussianMixtureModel, HyperbolicSecantMixtureModel, StudentMixtureModel, LaplaceMixtureModel, GumbelMixtureModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 真の分布の設定\n",
    "+ データ生成分布は変更しますが、混合比, 中心, scaleは同じものを流用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ratio = np.array([0.33, 0.33, 0.34])\n",
    "true_delta = 0\n",
    "true_s = np.array([[0.1, 0.1], [0.5, 0.5], [1, 1]])\n",
    "true_b = np.array([[2, 4], [-4, -2], [0, 0]])\n",
    "true_param = dict()\n",
    "true_param[\"ratio\"] = true_ratio\n",
    "true_param[\"mean\"] = true_b\n",
    "true_param[\"precision\"] = true_s\n",
    "true_param[\"scale\"] = np.array([np.diag(1/np.sqrt(true_s[k,:])) for k in range(len(true_ratio))])\n",
    "K0 = len(true_ratio)\n",
    "M = true_b.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 学習データの数\n",
    "n = 400\n",
    "\n",
    "### テストデータの数\n",
    "N = 10000\n",
    "\n",
    "### データの出方の個数\n",
    "ndataset = 50\n",
    "\n",
    "### 事前分布のハイパーパラメータ\n",
    "pri_params = {\n",
    "    \"pri_alpha\": 0.1,\n",
    "    \"pri_beta\": 0.001,\n",
    "    \"pri_gamma\": M+2,\n",
    "    \"pri_delta\": 1\n",
    "}\n",
    "\n",
    "### データ生成の回数\n",
    "data_seed_start = 201907\n",
    "data_seeds = np.arange(start = data_seed_start, stop = data_seed_start + ndataset, step = 1)\n",
    "\n",
    "### 学習モデルの初期値の乱数 -> データseedにoffsetを加えたものを使う\n",
    "learning_num = 10\n",
    "learning_seed_offset = 100\n",
    "\n",
    "### 繰り返しアルゴリズムの繰り返し回数\n",
    "learning_iteration = 1000\n",
    "\n",
    "### 学習モデルのコンポーネントの数\n",
    "K = np.array([3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> c:\\users\\user\\documents\\github\\learningmodels\\lib\\util\\prob.py(37)rvs()\n",
      "-> if data_seed > 0: np.random.seed(data_seed)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  ll\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34  \t    @classmethod\n",
      " 35  \t    def rvs(cls, ratio:np.ndarray, loc:np.ndarray, scale:np.ndarray, size:int=1, data_seed:int=-1,):\n",
      " 36  \t        import pdb; pdb.set_trace()\n",
      " 37  ->\t        if data_seed > 0: np.random.seed(data_seed)\n",
      " 38  \t        data_label = np.random.multinomial(n = 1, pvals = ratio, size = size)\n",
      " 39  \t        data_label_arg = np.argmax(data_label, axis = 1)\n",
      " 40  \t        X = np.array([[cls._rvs_component(loc[data_label_arg[i],j], scale[data_label_arg[i],j], size) for j in range(loc.shape[1])] for i in range(size)]).squeeze()\n",
      " 41  \t        return (X, data_label, data_label_arg)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  loc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 2,  4],\n",
      "       [-4, -2],\n",
      "       [ 0,  0]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  scale\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.1, 0.1],\n",
      "       [0.5, 0.5],\n",
      "       [1. , 1. ]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> c:\\users\\user\\documents\\github\\learningmodels\\lib\\util\\prob.py(38)rvs()\n",
      "-> data_label = np.random.multinomial(n = 1, pvals = ratio, size = size)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> c:\\users\\user\\documents\\github\\learningmodels\\lib\\util\\prob.py(39)rvs()\n",
      "-> data_label_arg = np.argmax(data_label, axis = 1)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  cls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'util.prob.GumbelMixtureModel'>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a302c3d111d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mGumbelMixtureModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\LearningModels\\lib\\util\\prob.py\u001b[0m in \u001b[0;36mrvs\u001b[1;34m(cls, ratio, loc, scale, size, data_seed)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata_seed\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_seed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mdata_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mdata_label_arg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rvs_component\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_label_arg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_label_arg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_label_arg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\LearningModels\\lib\\util\\prob.py\u001b[0m in \u001b[0;36mrvs\u001b[1;34m(cls, ratio, loc, scale, size, data_seed)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata_seed\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_seed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mdata_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mdata_label_arg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rvs_component\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_label_arg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_label_arg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_label_arg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;31m# None\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'line'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'call'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "GumbelMixtureModel.rvs(true_ratio, true_b, true_s, size=10)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 性能評価\n",
    "+ 1連の流れ\n",
    "    1. データ生成する\n",
    "    1. 学習を行う\n",
    "    1. 精度評価を行う\n",
    "    1. 1に戻って再度計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コンポーネントの分布が正規分布の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "gerror_gmm = np.zeros(len(data_seeds))\n",
    "cklerror_gmm = np.zeros(len(data_seeds))\n",
    "c01error_gmm = np.zeros(len(data_seeds))\n",
    "\n",
    "gerror_hsmm = np.zeros(len(data_seeds))\n",
    "cklerror_hsmm = np.zeros(len(data_seeds))\n",
    "c01error_hsmm = np.zeros(len(data_seeds))\n",
    "\n",
    "for i, data_seed in enumerate(data_seeds):\n",
    "    ### データを生成する\n",
    "    (train_X, train_label, train_label_arg) = GaussianMixtureModel.rvs(true_ratio, true_b, true_s, size = n, data_seed = data_seed)\n",
    "    (test_X, test_label, test_label_arg) = GaussianMixtureModel.rvs(true_ratio, true_b, true_s, size = N)\n",
    "    \n",
    "    gmm_diag_obj = GaussianMixtureModelVB(K = K[0],\n",
    "                                     pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                     iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset, method = \"diag\")\n",
    "    gmm_diag_obj.fit(train_X)\n",
    "    \n",
    "    hsmm_obj = HyperbolicSecantMixtureVB(K = K[0],                                     \n",
    "                                         pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                         iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset)\n",
    "    hsmm_obj.fit(train_X)\n",
    "    posterior_true_logprob = GaussianMixtureModel().latent_posterior_logprob(train_X, true_ratio, true_b, true_s)\n",
    "    cklerror_gmm[i] = gmm_diag_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    cklerror_hsmm[i] = hsmm_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    \n",
    "    c01error_gmm[i] = gmm_diag_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    c01error_hsmm[i] = hsmm_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    \n",
    "    true_empirical_entropy = -GaussianMixtureModel.logpdf(test_X, true_ratio, true_b, true_s)\n",
    "    gerror_gmm[i] = (-true_empirical_entropy - gmm_diag_obj.predict_logproba(test_X))/len(test_X)\n",
    "    gerror_hsmm[i] = (-true_empirical_entropy - hsmm_obj.predict_logproba(test_X))/len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gerror_gmm: 0.023986380276039432,\n",
      "gerror_hsmm: 0.04337281269765235,\n",
      "cklerror_gmm: 0.014579801789498532,\n",
      "cklerror_hsmm: 0.0709953482507086,\n",
      "c01error_gmm: 0.922,\n",
      "c01error_hsmm: 0.9018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "gerror_gmm: {gerror_gmm.mean()},\n",
    "gerror_hsmm: {gerror_hsmm.mean()},\n",
    "cklerror_gmm: {cklerror_gmm.mean()},\n",
    "cklerror_hsmm: {cklerror_hsmm.mean()},\n",
    "c01error_gmm: {c01error_gmm.mean()},\n",
    "c01error_hsmm: {c01error_hsmm.mean()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コンポーネントの分布が双曲線正割分布の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerror_gmm = np.zeros(len(data_seeds))\n",
    "cklerror_gmm = np.zeros(len(data_seeds))\n",
    "c01error_gmm = np.zeros(len(data_seeds))\n",
    "norm_energy_gmm = np.zeros(len(data_seeds))\n",
    "\n",
    "gerror_hsmm = np.zeros(len(data_seeds))\n",
    "cklerror_hsmm = np.zeros(len(data_seeds))\n",
    "c01error_hsmm = np.zeros(len(data_seeds))\n",
    "norm_energy_hsmm = np.zeros(len(data_seeds))\n",
    "\n",
    "for i, data_seed in enumerate(data_seeds):\n",
    "    ### データを生成する\n",
    "    (train_X, train_label, train_label_arg) = HyperbolicSecantMixtureModel.rvs(true_ratio, true_b, true_s, size = n, data_seed = data_seed)\n",
    "    (test_X, test_label, test_label_arg) = HyperbolicSecantMixtureModel.rvs(true_ratio, true_b, true_s, size = N)\n",
    "    \n",
    "    gmm_diag_obj = GaussianMixtureModelVB(K = K[0],\n",
    "                                     pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                     iteration = 1000, method = \"diag\", \n",
    "                                     restart_num=learning_num, learning_seed=data_seed + learning_seed_offset)\n",
    "    gmm_diag_obj.fit(train_X)\n",
    "    \n",
    "    hsmm_obj = HyperbolicSecantMixtureVB(K = K[0],                                     \n",
    "                                         pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                         iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset)\n",
    "    hsmm_obj.fit(train_X)\n",
    "    \n",
    "    posterior_true_logprob = HyperbolicSecantMixtureModel().latent_posterior_logprob(train_X, true_ratio, true_b, true_s)\n",
    "    cklerror_gmm[i] = gmm_diag_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    cklerror_hsmm[i] = hsmm_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    \n",
    "    c01error_gmm[i] = gmm_diag_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    c01error_hsmm[i] = hsmm_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    \n",
    "    true_empirical_entropy = -HyperbolicSecantMixtureModel.logpdf(test_X, true_ratio, true_b, true_s)\n",
    "    gerror_gmm[i] = (-true_empirical_entropy - gmm_diag_obj.predict_logproba(test_X))/len(test_X)\n",
    "    gerror_hsmm[i] = (-true_empirical_entropy - hsmm_obj.predict_logproba(test_X))/len(test_X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gerror_gmm: 0.07308802942641764, \n",
      "gerror_hsmm: 0.02797083078313875,\n",
      "cklerror_gmm: 23.58539566102074,\n",
      "cklerror_hsmm: 2.2496259780588606,\n",
      "c01error_gmm: 0.726,\n",
      "c01error_hsmm: 0.7832000000000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "gerror_gmm: {gerror_gmm.mean()}, \n",
    "gerror_hsmm: {gerror_hsmm.mean()},\n",
    "cklerror_gmm: {cklerror_gmm.mean()},\n",
    "cklerror_hsmm: {cklerror_hsmm.mean()},\n",
    "c01error_gmm: {c01error_gmm.mean()},\n",
    "c01error_hsmm: {c01error_hsmm.mean()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コンポーネントの分布がt分布の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerror_gmm = np.zeros(len(data_seeds))\n",
    "cklerror_gmm = np.zeros(len(data_seeds))\n",
    "c01error_gmm = np.zeros(len(data_seeds))\n",
    "# norm_energy_gmm = np.zeros(len(data_seeds))\n",
    "\n",
    "gerror_hsmm = np.zeros(len(data_seeds))\n",
    "cklerror_hsmm = np.zeros(len(data_seeds))\n",
    "c01error_hsmm = np.zeros(len(data_seeds))\n",
    "# norm_energy_hsmm = np.zeros(len(data_seeds))\n",
    "\n",
    "true_df = 3\n",
    "for i, data_seed in enumerate(data_seeds):\n",
    "    ### データを生成する\n",
    "    (train_X, train_label, train_label_arg) = StudentMixtureModel.rvs(true_ratio, true_b, true_s, size = n, data_seed = data_seed, df = true_df)\n",
    "    (test_X, test_label, test_label_arg) = StudentMixtureModel.rvs(true_ratio, true_b, true_s, size = N, df = true_df)\n",
    "    \n",
    "    gmm_diag_obj = GaussianMixtureModelVB(K = K[0],\n",
    "                                     pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                     iteration = 1000, method = \"diag\", \n",
    "                                     restart_num=learning_num, learning_seed=data_seed + learning_seed_offset)\n",
    "    gmm_diag_obj.fit(train_X)\n",
    "    \n",
    "    hsmm_obj = HyperbolicSecantMixtureVB(K = K[0],                                     \n",
    "                                         pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                         iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset)\n",
    "    hsmm_obj.fit(train_X)\n",
    "    \n",
    "    posterior_true_logprob = StudentMixtureModel().latent_posterior_logprob(train_X, true_ratio, true_b, true_s, df = true_df)\n",
    "    cklerror_gmm[i] = gmm_diag_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    cklerror_hsmm[i] = hsmm_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)    \n",
    "    \n",
    "    c01error_gmm[i] = gmm_diag_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    c01error_hsmm[i] = hsmm_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    \n",
    "    true_empirical_entropy = -StudentMixtureModel.logpdf(test_X, true_ratio, true_b, true_s, df = true_df)\n",
    "    gerror_gmm[i] = (-true_empirical_entropy - gmm_diag_obj.predict_logproba(test_X))/len(test_X)\n",
    "    gerror_hsmm[i] = (-true_empirical_entropy - hsmm_obj.predict_logproba(test_X))/len(test_X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gerror_gmm: 0.19620487509839105,\n",
      "gerror_hsmm: 0.03907924619254339,\n",
      "cklerror_gmm: 3.719392759549088,\n",
      "cklerror_hsmm: 1.5787704723958722,\n",
      "c01error_gmm: 0.7676500000000002,\n",
      "c01error_hsmm: 0.8492999999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "gerror_gmm: {gerror_gmm.mean()},\n",
    "gerror_hsmm: {gerror_hsmm.mean()},\n",
    "cklerror_gmm: {cklerror_gmm.mean()},\n",
    "cklerror_hsmm: {cklerror_hsmm.mean()},\n",
    "c01error_gmm: {c01error_gmm.mean()},\n",
    "c01error_hsmm: {c01error_hsmm.mean()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コンポーネントの分布がラプラス分布の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerror_gmm = np.zeros(len(data_seeds))\n",
    "cklerror_gmm = np.zeros(len(data_seeds))\n",
    "c01error_gmm = np.zeros(len(data_seeds))\n",
    "# norm_energy_gmm = np.zeros(len(data_seeds))\n",
    "\n",
    "gerror_hsmm = np.zeros(len(data_seeds))\n",
    "cklerror_hsmm = np.zeros(len(data_seeds))\n",
    "c01error_hsmm = np.zeros(len(data_seeds))\n",
    "# norm_energy_hsmm = np.zeros(len(data_seeds))\n",
    "\n",
    "for i, data_seed in enumerate(data_seeds):\n",
    "    ### データを生成する\n",
    "    (train_X, train_label, train_label_arg) = LaplaceMixtureModel.rvs(true_ratio, true_b, true_s, size = n, data_seed = data_seed)\n",
    "    (test_X, test_label, test_label_arg) = LaplaceMixtureModel.rvs(true_ratio, true_b, true_s, size = N)\n",
    "    \n",
    "    gmm_diag_obj = GaussianMixtureModelVB(K = K[0],\n",
    "                                     pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                     iteration = 1000, method = \"diag\", \n",
    "                                     restart_num=learning_num, learning_seed=data_seed + learning_seed_offset)\n",
    "    gmm_diag_obj.fit(train_X)\n",
    "    \n",
    "    hsmm_obj = HyperbolicSecantMixtureVB(K = K[0],                                     \n",
    "                                         pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                         iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset)\n",
    "    hsmm_obj.fit(train_X)\n",
    "    \n",
    "    posterior_true_logprob = LaplaceMixtureModel().latent_posterior_logprob(train_X, true_ratio, true_b, true_s)\n",
    "    cklerror_gmm[i] = gmm_diag_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    cklerror_hsmm[i] = hsmm_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)   \n",
    "    \n",
    "    c01error_gmm[i] = gmm_diag_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    c01error_hsmm[i] = hsmm_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    \n",
    "    true_empirical_entropy = -LaplaceMixtureModel.logpdf(test_X, true_ratio, true_b, true_s)\n",
    "    gerror_gmm[i] = (-true_empirical_entropy - gmm_diag_obj.predict_logproba(test_X))/len(test_X)\n",
    "    gerror_hsmm[i] = (-true_empirical_entropy - hsmm_obj.predict_logproba(test_X))/len(test_X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gerror_gmm: 0.10545562558925133,\n",
      "gerror_hsmm: 0.03266588382364332,\n",
      "cklerror_gmm: 1.7618997379222217,\n",
      "cklerror_hsmm: 1.4220849553036825,\n",
      "c01error_gmm: 0.7943000000000001,\n",
      "c01error_hsmm: 0.8590000000000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "gerror_gmm: {gerror_gmm.mean()},\n",
    "gerror_hsmm: {gerror_hsmm.mean()},\n",
    "cklerror_gmm: {cklerror_gmm.mean()},\n",
    "cklerror_hsmm: {cklerror_hsmm.mean()},\n",
    "c01error_gmm: {c01error_gmm.mean()},\n",
    "c01error_hsmm: {c01error_hsmm.mean()}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
