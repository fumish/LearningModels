{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSMMの性能比較の数値実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from IPython.core.display import display, Markdown, Latex\n",
    "import numpy as np\n",
    "from scipy.special import gammaln, psi\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm, t, cauchy, laplace, gumbel_r, gamma, skewnorm, pareto, multivariate_normal\n",
    "from typing import Callable\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "\n",
    "from HyperbolicSecantMixtureModelVB import HyperbolicSecantMixtureVB\n",
    "from learning import GaussianMixtureModelVB\n",
    "from util import GaussianMixtureModel, HyperbolicSecantMixtureModel, StudentMixtureModel, LaplaceMixtureModel, GumbelMixtureModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 真の分布の設定\n",
    "+ データ生成分布は変更しますが、混合比, 中心, scaleは同じものを流用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ratio = np.array([0.33, 0.33, 0.34])\n",
    "true_delta = 0\n",
    "true_s = np.array([[2, 2], [0.5, 0.5], [1, 1]])\n",
    "true_b = np.array([[2, 4], [-4, -2], [0, 0]])\n",
    "true_param = dict()\n",
    "true_param[\"ratio\"] = true_ratio\n",
    "true_param[\"mean\"] = true_b\n",
    "true_param[\"precision\"] = true_s\n",
    "true_param[\"scale\"] = np.array([np.diag(1/np.sqrt(true_s[k,:])) for k in range(len(true_ratio))])\n",
    "K0 = len(true_ratio)\n",
    "M = true_b.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 学習データの数\n",
    "n = 400\n",
    "\n",
    "### テストデータの数\n",
    "N = 10000\n",
    "\n",
    "### データの出方の個数\n",
    "ndataset = 50\n",
    "\n",
    "### 事前分布のハイパーパラメータ\n",
    "pri_params = {\n",
    "    \"pri_alpha\": 0.1,\n",
    "    \"pri_beta\": 0.001,\n",
    "    \"pri_gamma\": M+2,\n",
    "    \"pri_delta\": 1\n",
    "}\n",
    "\n",
    "### データ生成の回数\n",
    "data_seed_start = 201907\n",
    "data_seeds = np.arange(start = data_seed_start, stop = data_seed_start + ndataset, step = 1)\n",
    "\n",
    "### 学習モデルの初期値の乱数 -> データseedにoffsetを加えたものを使う\n",
    "learning_num = 10\n",
    "learning_seed_offset = 100\n",
    "\n",
    "### 繰り返しアルゴリズムの繰り返し回数\n",
    "learning_iteration = 1000\n",
    "\n",
    "### 学習モデルのコンポーネントの数\n",
    "K = np.array([3, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 性能評価\n",
    "+ 1連の流れ\n",
    "    1. データ生成する\n",
    "    1. 学習を行う\n",
    "    1. 精度評価を行う\n",
    "    1. 1に戻って再度計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コンポーネントの分布が正規分布の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "gerror_gmm_diag = np.zeros(len(data_seeds))\n",
    "cklerror_gmm_diag = np.zeros(len(data_seeds))\n",
    "c01error_gmm_diag = np.zeros(len(data_seeds))\n",
    "\n",
    "gerror_gmm_cov = np.zeros(len(data_seeds))\n",
    "cklerror_gmm_cov = np.zeros(len(data_seeds))\n",
    "c01error_gmm_cov = np.zeros(len(data_seeds))\n",
    "\n",
    "gerror_hsmm = np.zeros(len(data_seeds))\n",
    "cklerror_hsmm = np.zeros(len(data_seeds))\n",
    "c01error_hsmm = np.zeros(len(data_seeds))\n",
    "\n",
    "for i, data_seed in enumerate(data_seeds):\n",
    "    ### データを生成する\n",
    "    (train_X, train_label, train_label_arg) = GaussianMixtureModel.rvs(true_ratio, true_b, true_s, size = n, data_seed = data_seed)\n",
    "    (test_X, test_label, test_label_arg) = GaussianMixtureModel.rvs(true_ratio, true_b, true_s, size = N)\n",
    "    \n",
    "    gmm_diag_obj = GaussianMixtureModelVB(K = K[0],\n",
    "                                     pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                     iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset, method = \"diag\")\n",
    "    gmm_diag_obj.fit(train_X)\n",
    "    \n",
    "    gmm_cov_obj = GaussianMixtureModelVB(K = K[0],\n",
    "                                     pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                     iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset, method = \"full\")\n",
    "    gmm_cov_obj.fit(train_X)\n",
    "    \n",
    "    hsmm_obj = HyperbolicSecantMixtureVB(K = K[0],                                     \n",
    "                                         pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                         iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset)\n",
    "    hsmm_obj.fit(train_X)\n",
    "    posterior_true_logprob = GaussianMixtureModel().latent_posterior_logprob(train_X, true_ratio, true_b, true_s)\n",
    "    cklerror_gmm_diag[i] = gmm_diag_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    cklerror_gmm_cov[i] = gmm_cov_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    cklerror_hsmm[i] = hsmm_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    \n",
    "    c01error_gmm_diag[i] = gmm_diag_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    c01error_gmm_cov[i] = gmm_cov_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    c01error_hsmm[i] = hsmm_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    \n",
    "    true_empirical_entropy = -GaussianMixtureModel.logpdf(test_X, true_ratio, true_b, true_s)\n",
    "    gerror_gmm_diag[i] = (-true_empirical_entropy - gmm_diag_obj.predict_logproba(test_X))/len(test_X)\n",
    "    gerror_gmm_cov[i] = (-true_empirical_entropy - gmm_cov_obj.predict_logproba(test_X))/len(test_X)\n",
    "    gerror_hsmm[i] = (-true_empirical_entropy - hsmm_obj.predict_logproba(test_X))/len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gerror_gmm_diag: 0.02279932711705087,\n",
      "gerror_gmm_cov: 0.026461245602702164,\n",
      "gerror_hsmm: 0.05473828618846722,\n",
      "cklerror_gmm_diag: 0.006193283216543171,\n",
      "cklerror_gmm_cov: 0.010147847371069415,\n",
      "cklerror_hsmm: 0.016026883738220293,\n",
      "c01error_gmm_diag: 0.9762499999999998,\n",
      "c01error_gmm_cov: 0.9752000000000001,\n",
      "c01error_hsmm: 0.9734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "gerror_gmm_diag: {gerror_gmm_diag.mean()},\n",
    "gerror_gmm_cov: {gerror_gmm_cov.mean()},\n",
    "gerror_hsmm: {gerror_hsmm.mean()},\n",
    "cklerror_gmm_diag: {cklerror_gmm_diag.mean()},\n",
    "cklerror_gmm_cov: {cklerror_gmm_cov.mean()},\n",
    "cklerror_hsmm: {cklerror_hsmm.mean()},\n",
    "c01error_gmm_diag: {c01error_gmm_diag.mean()},\n",
    "c01error_gmm_cov: {c01error_gmm_cov.mean()},\n",
    "c01error_hsmm: {c01error_hsmm.mean()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コンポーネントの分布が双曲線正割分布の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerror_gmm_diag = np.zeros(len(data_seeds))\n",
    "cklerror_gmm_diag = np.zeros(len(data_seeds))\n",
    "c01error_gmm_diag = np.zeros(len(data_seeds))\n",
    "\n",
    "gerror_gmm_cov = np.zeros(len(data_seeds))\n",
    "cklerror_gmm_cov = np.zeros(len(data_seeds))\n",
    "c01error_gmm_cov = np.zeros(len(data_seeds))\n",
    "\n",
    "gerror_hsmm = np.zeros(len(data_seeds))\n",
    "cklerror_hsmm = np.zeros(len(data_seeds))\n",
    "c01error_hsmm = np.zeros(len(data_seeds))\n",
    "for i, data_seed in enumerate(data_seeds):\n",
    "    ### データを生成する\n",
    "    (train_X, train_label, train_label_arg) = HyperbolicSecantMixtureModel.rvs(true_ratio, true_b, true_s, size = n, data_seed = data_seed)\n",
    "    (test_X, test_label, test_label_arg) = HyperbolicSecantMixtureModel.rvs(true_ratio, true_b, true_s, size = N)\n",
    "    \n",
    "    gmm_diag_obj = GaussianMixtureModelVB(K = K[0],\n",
    "                                     pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                     iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset, method = \"diag\")\n",
    "    gmm_diag_obj.fit(train_X)\n",
    "    \n",
    "    gmm_cov_obj = GaussianMixtureModelVB(K = K[0],\n",
    "                                     pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                     iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset, method = \"full\")\n",
    "    gmm_cov_obj.fit(train_X)\n",
    "    \n",
    "    hsmm_obj = HyperbolicSecantMixtureVB(K = K[0],                                     \n",
    "                                         pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                         iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset)\n",
    "    hsmm_obj.fit(train_X)\n",
    "    \n",
    "    posterior_true_logprob = HyperbolicSecantMixtureModel().latent_posterior_logprob(train_X, true_ratio, true_b, true_s)\n",
    "    cklerror_gmm_diag[i] = gmm_diag_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    cklerror_gmm_cov[i] = gmm_cov_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    cklerror_hsmm[i] = hsmm_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    \n",
    "    c01error_gmm_diag[i] = gmm_diag_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    c01error_gmm_cov[i] = gmm_cov_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    c01error_hsmm[i] = hsmm_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    \n",
    "    true_empirical_entropy = -HyperbolicSecantMixtureModel.logpdf(test_X, true_ratio, true_b, true_s)\n",
    "    gerror_gmm_diag[i] = (-true_empirical_entropy - gmm_diag_obj.predict_logproba(test_X))/len(test_X)\n",
    "    gerror_gmm_cov[i] = (-true_empirical_entropy - gmm_cov_obj.predict_logproba(test_X))/len(test_X)\n",
    "    gerror_hsmm[i] = (-true_empirical_entropy - hsmm_obj.predict_logproba(test_X))/len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gerror_gmm_diag: -0.6083380371753834,\n",
      "gerror_gmm_cov: -0.612315429116236,\n",
      "gerror_hsmm: -0.6456245458137825,\n",
      "cklerror_gmm_diag: 5.331679934170414,\n",
      "cklerror_gmm_cov: 5.610586460541836,\n",
      "cklerror_hsmm: 0.9137027064185334,\n",
      "c01error_gmm_diag: 0.8671999999999999,\n",
      "c01error_gmm_cov: 0.8568499999999999,\n",
      "c01error_hsmm: 0.8957999999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "gerror_gmm_diag: {gerror_gmm_diag.mean()},\n",
    "gerror_gmm_cov: {gerror_gmm_cov.mean()},\n",
    "gerror_hsmm: {gerror_hsmm.mean()},\n",
    "cklerror_gmm_diag: {cklerror_gmm_diag.mean()},\n",
    "cklerror_gmm_cov: {cklerror_gmm_cov.mean()},\n",
    "cklerror_hsmm: {cklerror_hsmm.mean()},\n",
    "c01error_gmm_diag: {c01error_gmm_diag.mean()},\n",
    "c01error_gmm_cov: {c01error_gmm_cov.mean()},\n",
    "c01error_hsmm: {c01error_hsmm.mean()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コンポーネントの分布がt分布の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerror_gmm_diag = np.zeros(len(data_seeds))\n",
    "cklerror_gmm_diag = np.zeros(len(data_seeds))\n",
    "c01error_gmm_diag = np.zeros(len(data_seeds))\n",
    "\n",
    "gerror_gmm_cov = np.zeros(len(data_seeds))\n",
    "cklerror_gmm_cov = np.zeros(len(data_seeds))\n",
    "c01error_gmm_cov = np.zeros(len(data_seeds))\n",
    "\n",
    "gerror_hsmm = np.zeros(len(data_seeds))\n",
    "cklerror_hsmm = np.zeros(len(data_seeds))\n",
    "c01error_hsmm = np.zeros(len(data_seeds))\n",
    "\n",
    "true_df = 3\n",
    "for i, data_seed in enumerate(data_seeds):\n",
    "    ### データを生成する\n",
    "    (train_X, train_label, train_label_arg) = StudentMixtureModel.rvs(true_ratio, true_b, true_s, size = n, data_seed = data_seed, df = true_df)\n",
    "    (test_X, test_label, test_label_arg) = StudentMixtureModel.rvs(true_ratio, true_b, true_s, size = N, df = true_df)\n",
    "    \n",
    "    gmm_diag_obj = GaussianMixtureModelVB(K = K[0],\n",
    "                                     pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                     iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset, method = \"diag\")\n",
    "    gmm_diag_obj.fit(train_X)\n",
    "    \n",
    "    gmm_cov_obj = GaussianMixtureModelVB(K = K[0],\n",
    "                                     pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                     iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset, method = \"full\")\n",
    "    gmm_cov_obj.fit(train_X)\n",
    "    \n",
    "    hsmm_obj = HyperbolicSecantMixtureVB(K = K[0],                                     \n",
    "                                         pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                         iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset)\n",
    "    hsmm_obj.fit(train_X)\n",
    "    \n",
    "    posterior_true_logprob = StudentMixtureModel().latent_posterior_logprob(train_X, true_ratio, true_b, true_s, df = true_df)\n",
    "    cklerror_gmm_diag[i] = gmm_diag_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    cklerror_gmm_cov[i] = gmm_cov_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    cklerror_hsmm[i] = hsmm_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    \n",
    "    c01error_gmm_diag[i] = gmm_diag_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    c01error_gmm_cov[i] = gmm_cov_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    c01error_hsmm[i] = hsmm_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    \n",
    "    true_empirical_entropy = -StudentMixtureModel.logpdf(test_X, true_ratio, true_b, true_s, df = true_df)\n",
    "    gerror_gmm_diag[i] = (-true_empirical_entropy - gmm_diag_obj.predict_logproba(test_X))/len(test_X)\n",
    "    gerror_gmm_cov[i] = (-true_empirical_entropy - gmm_cov_obj.predict_logproba(test_X))/len(test_X)\n",
    "    gerror_hsmm[i] = (-true_empirical_entropy - hsmm_obj.predict_logproba(test_X))/len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gerror_gmm_diag: 0.19055017386161752,\n",
      "gerror_gmm_cov: 0.19093998161244208,\n",
      "gerror_hsmm: 0.047143602214668894,\n",
      "cklerror_gmm_diag: 1.326964762751781,\n",
      "cklerror_gmm_cov: 1.9558436129389745,\n",
      "cklerror_hsmm: 0.040873788363285486,\n",
      "c01error_gmm_diag: 0.8486000000000001,\n",
      "c01error_gmm_cov: 0.7792999999999999,\n",
      "c01error_hsmm: 0.9077500000000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "gerror_gmm_diag: {gerror_gmm_diag.mean()},\n",
    "gerror_gmm_cov: {gerror_gmm_cov.mean()},\n",
    "gerror_hsmm: {gerror_hsmm.mean()},\n",
    "cklerror_gmm_diag: {cklerror_gmm_diag.mean()},\n",
    "cklerror_gmm_cov: {cklerror_gmm_cov.mean()},\n",
    "cklerror_hsmm: {cklerror_hsmm.mean()},\n",
    "c01error_gmm_diag: {c01error_gmm_diag.mean()},\n",
    "c01error_gmm_cov: {c01error_gmm_cov.mean()},\n",
    "c01error_hsmm: {c01error_hsmm.mean()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コンポーネントの分布がラプラス分布の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerror_gmm_diag = np.zeros(len(data_seeds))\n",
    "cklerror_gmm_diag = np.zeros(len(data_seeds))\n",
    "c01error_gmm_diag = np.zeros(len(data_seeds))\n",
    "\n",
    "gerror_gmm_cov = np.zeros(len(data_seeds))\n",
    "cklerror_gmm_cov = np.zeros(len(data_seeds))\n",
    "c01error_gmm_cov = np.zeros(len(data_seeds))\n",
    "\n",
    "gerror_hsmm = np.zeros(len(data_seeds))\n",
    "cklerror_hsmm = np.zeros(len(data_seeds))\n",
    "c01error_hsmm = np.zeros(len(data_seeds))\n",
    "\n",
    "for i, data_seed in enumerate(data_seeds):\n",
    "    ### データを生成する\n",
    "    (train_X, train_label, train_label_arg) = LaplaceMixtureModel.rvs(true_ratio, true_b, true_s, size = n, data_seed = data_seed)\n",
    "    (test_X, test_label, test_label_arg) = LaplaceMixtureModel.rvs(true_ratio, true_b, true_s, size = N)\n",
    "    \n",
    "    gmm_diag_obj = GaussianMixtureModelVB(K = K[0],\n",
    "                                     pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                     iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset, method = \"diag\")\n",
    "    gmm_diag_obj.fit(train_X)\n",
    "    \n",
    "    gmm_cov_obj = GaussianMixtureModelVB(K = K[0],\n",
    "                                     pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                     iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset, method = \"full\")\n",
    "    gmm_cov_obj.fit(train_X)\n",
    "    \n",
    "    hsmm_obj = HyperbolicSecantMixtureVB(K = K[0],                                     \n",
    "                                         pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                         iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset)\n",
    "    hsmm_obj.fit(train_X)\n",
    "    \n",
    "    posterior_true_logprob = LaplaceMixtureModel().latent_posterior_logprob(train_X, true_ratio, true_b, true_s)\n",
    "    cklerror_gmm_diag[i] = gmm_diag_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    cklerror_gmm_cov[i] = gmm_cov_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    cklerror_hsmm[i] = hsmm_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    \n",
    "    c01error_gmm_diag[i] = gmm_diag_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    c01error_gmm_cov[i] = gmm_cov_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    c01error_hsmm[i] = hsmm_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    \n",
    "    true_empirical_entropy = -LaplaceMixtureModel.logpdf(test_X, true_ratio, true_b, true_s)\n",
    "    gerror_gmm_diag[i] = (-true_empirical_entropy - gmm_diag_obj.predict_logproba(test_X))/len(test_X)\n",
    "    gerror_gmm_cov[i] = (-true_empirical_entropy - gmm_cov_obj.predict_logproba(test_X))/len(test_X)\n",
    "    gerror_hsmm[i] = (-true_empirical_entropy - hsmm_obj.predict_logproba(test_X))/len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gerror_gmm_diag: 0.11165531322790817,\n",
      "gerror_gmm_cov: 0.10232204767039439,\n",
      "gerror_hsmm: 0.041312681302911464,\n",
      "cklerror_gmm_diag: 0.5307592658959779,\n",
      "cklerror_gmm_cov: 0.7679928267586058,\n",
      "cklerror_hsmm: 0.014391864075189225,\n",
      "c01error_gmm_diag: 0.87155,\n",
      "c01error_gmm_cov: 0.8409500000000001,\n",
      "c01error_hsmm: 0.9197500000000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "gerror_gmm_diag: {gerror_gmm_diag.mean()},\n",
    "gerror_gmm_cov: {gerror_gmm_cov.mean()},\n",
    "gerror_hsmm: {gerror_hsmm.mean()},\n",
    "cklerror_gmm_diag: {cklerror_gmm_diag.mean()},\n",
    "cklerror_gmm_cov: {cklerror_gmm_cov.mean()},\n",
    "cklerror_hsmm: {cklerror_hsmm.mean()},\n",
    "c01error_gmm_diag: {c01error_gmm_diag.mean()},\n",
    "c01error_gmm_cov: {c01error_gmm_cov.mean()},\n",
    "c01error_hsmm: {c01error_hsmm.mean()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コンポーネントの分布がガンベル分布の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerror_gmm_diag = np.zeros(len(data_seeds))\n",
    "cklerror_gmm_diag = np.zeros(len(data_seeds))\n",
    "c01error_gmm_diag = np.zeros(len(data_seeds))\n",
    "\n",
    "gerror_gmm_cov = np.zeros(len(data_seeds))\n",
    "cklerror_gmm_cov = np.zeros(len(data_seeds))\n",
    "c01error_gmm_cov = np.zeros(len(data_seeds))\n",
    "\n",
    "gerror_hsmm = np.zeros(len(data_seeds))\n",
    "cklerror_hsmm = np.zeros(len(data_seeds))\n",
    "c01error_hsmm = np.zeros(len(data_seeds))\n",
    "\n",
    "for i, data_seed in enumerate(data_seeds):\n",
    "    ### データを生成する\n",
    "    (train_X, train_label, train_label_arg) = GumbelMixtureModel.rvs(true_ratio, true_b, true_s, size = n, data_seed = data_seed)\n",
    "    (test_X, test_label, test_label_arg) = GumbelMixtureModel.rvs(true_ratio, true_b, true_s, size = N)\n",
    "    \n",
    "    gmm_diag_obj = GaussianMixtureModelVB(K = K[0],\n",
    "                                     pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                     iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset, method = \"diag\")\n",
    "    gmm_diag_obj.fit(train_X)\n",
    "    \n",
    "    gmm_cov_obj = GaussianMixtureModelVB(K = K[0],\n",
    "                                     pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                     iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset, method = \"full\")\n",
    "    gmm_cov_obj.fit(train_X)\n",
    "    \n",
    "    hsmm_obj = HyperbolicSecantMixtureVB(K = K[0],                                     \n",
    "                                         pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                         iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset)\n",
    "    hsmm_obj.fit(train_X)\n",
    "    \n",
    "    posterior_true_logprob = GumbelMixtureModel().latent_posterior_logprob(train_X, true_ratio, true_b, true_s)\n",
    "    cklerror_gmm_diag[i] = gmm_diag_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    cklerror_gmm_cov[i] = gmm_cov_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    cklerror_hsmm[i] = hsmm_obj.score_latent_kl(posterior_true_logprob)[0]/len(train_X)\n",
    "    \n",
    "    c01error_gmm_diag[i] = gmm_diag_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    c01error_gmm_cov[i] = gmm_cov_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    c01error_hsmm[i] = hsmm_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "    \n",
    "    true_empirical_entropy = -GumbelMixtureModel.logpdf(test_X, true_ratio, true_b, true_s)\n",
    "    gerror_gmm_diag[i] = (-true_empirical_entropy - gmm_diag_obj.predict_logproba(test_X))/len(test_X)\n",
    "    gerror_gmm_cov[i] = (-true_empirical_entropy - gmm_cov_obj.predict_logproba(test_X))/len(test_X)\n",
    "    gerror_hsmm[i] = (-true_empirical_entropy - hsmm_obj.predict_logproba(test_X))/len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gerror_gmm_diag: 0.12751395425148704,\n",
      "gerror_gmm_cov: 0.13714497681592203,\n",
      "gerror_hsmm: 0.12349520762503582,\n",
      "cklerror_gmm_diag: 0.21204404226924958,\n",
      "cklerror_gmm_cov: 2.4416294394576115,\n",
      "cklerror_hsmm: 0.041688194133492375,\n",
      "c01error_gmm_diag: 0.9226499999999999,\n",
      "c01error_gmm_cov: 0.8978,\n",
      "c01error_hsmm: 0.9361999999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "gerror_gmm_diag: {gerror_gmm_diag.mean()},\n",
    "gerror_gmm_cov: {gerror_gmm_cov.mean()},\n",
    "gerror_hsmm: {gerror_hsmm.mean()},\n",
    "cklerror_gmm_diag: {cklerror_gmm_diag.mean()},\n",
    "cklerror_gmm_cov: {cklerror_gmm_cov.mean()},\n",
    "cklerror_hsmm: {cklerror_hsmm.mean()},\n",
    "c01error_gmm_diag: {c01error_gmm_diag.mean()},\n",
    "c01error_gmm_cov: {c01error_gmm_cov.mean()},\n",
    "c01error_hsmm: {c01error_hsmm.mean()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For real data\n",
    "+ Fisher's iris data are used.\n",
    "+ generalization loss and 01 loss are calculated here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.871, 3.053, 3.831, 1.23 ])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを生成する\n",
    "data = load_iris()\n",
    "total_data = data.data\n",
    "mean_val = total_data.mean(axis = 0)\n",
    "std_val = total_data.std(axis = 0)\n",
    "total_X = (total_data - mean_val)/std_val\n",
    "\n",
    "n = 100\n",
    "N = total_X.shape[0] - n\n",
    "shuffled_ind = np.random.permutation(n + N)\n",
    "train_ind = shuffled_ind[:n]\n",
    "test_ind = shuffled_ind[n:]\n",
    "\n",
    "train_X = total_X[train_ind,2:]\n",
    "train_label_arg = data.target[train_ind]\n",
    "test_X = total_X[test_ind,2:]\n",
    "test_label_arg = data.target[test_ind,]\n",
    "n, M = train_X.shape\n",
    "\n",
    "gmm_diag_obj = GaussianMixtureModelVB(K = K[0],\n",
    "                                 pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                 iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset, method = \"diag\")\n",
    "gmm_diag_obj.fit(train_X)\n",
    "\n",
    "gmm_cov_obj = GaussianMixtureModelVB(K = K[0],\n",
    "                                 pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                 iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset, method = \"full\")\n",
    "gmm_cov_obj.fit(train_X)\n",
    "\n",
    "hsmm_obj = HyperbolicSecantMixtureVB(K = K[0],                                     \n",
    "                                     pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                     iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset)\n",
    "hsmm_obj.fit(train_X)\n",
    "\n",
    "c01error_gmm_diag = gmm_diag_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "c01error_gmm_cov = gmm_cov_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "c01error_hsmm = hsmm_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "\n",
    "gerror_gmm_diag = - gmm_diag_obj.predict_logproba(test_X)/len(test_X)\n",
    "gerror_gmm_cov=  - gmm_cov_obj.predict_logproba(test_X)/len(test_X)\n",
    "gerror_hsmm = - hsmm_obj.predict_logproba(test_X)/len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gerror_gmm_diag: 1.0622409949941989,\n",
      "gerror_gmm_cov: 0.9188617165949486,\n",
      "gerror_hsmm: 2.078860654802859,\n",
      "c01error_gmm_diag: 0.95,\n",
      "c01error_gmm_cov: 0.67,\n",
      "c01error_hsmm: 0.67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "gerror_gmm_diag: {gerror_gmm_diag},\n",
    "gerror_gmm_cov: {gerror_gmm_cov},\n",
    "gerror_hsmm: {gerror_hsmm},\n",
    "c01error_gmm_diag: {c01error_gmm_diag},\n",
    "c01error_gmm_cov: {c01error_gmm_cov},\n",
    "c01error_hsmm: {c01error_hsmm}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For real data\n",
    "+ wine data are used.\n",
    "+ generalization loss and 01 loss are calculated here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを生成する\n",
    "data = load_wine()\n",
    "total_data = data.data\n",
    "mean_val = total_data.mean(axis = 0)\n",
    "std_val = total_data.std(axis = 0)\n",
    "total_X = (total_data - mean_val)/std_val\n",
    "\n",
    "n = 150\n",
    "N = total_X.shape[0] - n\n",
    "shuffled_ind = np.random.permutation(n + N)\n",
    "train_ind = shuffled_ind[:n]\n",
    "test_ind = shuffled_ind[n:]\n",
    "\n",
    "train_X = total_X[train_ind,2:]\n",
    "train_label_arg = data.target[train_ind]\n",
    "test_X = total_X[test_ind,2:]\n",
    "test_label_arg = data.target[test_ind,]\n",
    "n, M = train_X.shape\n",
    "\n",
    "gmm_diag_obj = GaussianMixtureModelVB(K = K[1],\n",
    "                                 pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                 iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset, method = \"diag\")\n",
    "gmm_diag_obj.fit(train_X)\n",
    "\n",
    "gmm_cov_obj = GaussianMixtureModelVB(K = K[1],\n",
    "                                 pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = 15, pri_delta = pri_params[\"pri_delta\"], \n",
    "                                 iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset, method = \"full\")\n",
    "gmm_cov_obj.fit(train_X)\n",
    "\n",
    "hsmm_obj = HyperbolicSecantMixtureVB(K = K[1],                                     \n",
    "                                     pri_alpha = pri_params[\"pri_alpha\"], pri_beta = pri_params[\"pri_beta\"], pri_gamma = pri_params[\"pri_gamma\"], pri_delta = pri_params[\"pri_delta\"], \n",
    "                                     iteration = 1000, restart_num=learning_num, learning_seed=data_seed + learning_seed_offset)\n",
    "hsmm_obj.fit(train_X)\n",
    "\n",
    "c01error_gmm_diag = gmm_diag_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "c01error_gmm_cov = gmm_cov_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "c01error_hsmm = hsmm_obj.score_clustering(train_label_arg)[0]/len(train_X)\n",
    "\n",
    "gerror_gmm_diag = - gmm_diag_obj.predict_logproba(test_X)/len(test_X)\n",
    "gerror_gmm_cov=  - gmm_cov_obj.predict_logproba(test_X)/len(test_X)\n",
    "gerror_hsmm = - hsmm_obj.predict_logproba(test_X)/len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gerror_gmm_diag: 13.431477556597226,\n",
      "gerror_gmm_cov: 15.858975243742805,\n",
      "gerror_hsmm: 13.534744234046988,\n",
      "c01error_gmm_diag: 0.86,\n",
      "c01error_gmm_cov: 0.5666666666666667,\n",
      "c01error_hsmm: 0.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "gerror_gmm_diag: {gerror_gmm_diag},\n",
    "gerror_gmm_cov: {gerror_gmm_cov},\n",
    "gerror_hsmm: {gerror_hsmm},\n",
    "c01error_gmm_diag: {c01error_gmm_diag},\n",
    "c01error_gmm_cov: {c01error_gmm_cov},\n",
    "c01error_hsmm: {c01error_hsmm}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
