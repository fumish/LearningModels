{
    "collab_server" : "",
    "contents" : "input.unif.generate <- function(n,M,seed=1, xrange=c(0,1)){\n  set.seed(seed)\n  xrange <- c(-5,5)\n  x <- matrix(runif(n*M,min=xrange[1],max=xrange[2]), nrow = n, ncol=M)\n  return(x)\n}\n\nparam.norm.generate <- function(M,seed=1,mean=0,sd=1){\n  set.seed(seed)\n  true.param <- rnorm(M,mean = mean, sd = sd)\n  return(true.param)\n}\n\nparam.mixture.norm.generate <- function(M, K, seed=1, mean=0, sd=1, phi=1){\n  set.seed(seed)\n  tmp <- rgamma(K, shape=phi)\n  ratio <- tmp/sum(tmp)\n  \n  weight <- matrix(rnorm(M*K, mean=mean, sd=sd), nrow = M, ncol=K)\n  return(list(ratio=ratio, weight=weight))\n}\n\noutput.logistic.generate <- function(n,x,param,seed=1){\n  set.seed(seed)\n  # y <- numeric(n)\n  \n  p <- 1/(1 + exp(-x %*% param))\n  random.val <- runif(n)\n  # print(data.frame(p,random.val,random.val<p))\n  return(as.integer(random.val < p))\n  \n}\n\noutput.mixture.logistic.generate <- function(n, x, param, seed=1){\n  set.seed(seed)\n  \n  y <- numeric(n)\n  label.realization <- rmultinom(n, size=1, prob=param$ratio)\n  label <- apply(label.realization, 2, which.max)\n  for(i in 1:n){\n    i.weight <- param$weight[,label[i]]\n    i.p <- 1/(1+exp(-t(x[i,])%*%i.weight))\n    random.val <- runif(1)\n    y[i] <- as.integer(random.val < i.p)\n  }\n  \n  return(list(output=y, label=label))\n}\n\nLVA.logistic.regression <- function(x,y,beta = 0.001,iteration=100, seed=1, init.mean=0, init.sd=1){\n  set.seed(seed)\n  \n  n <- nrow(x)\n  M <- ncol(x)\n  \n  ##initial setting\n  h.ksi <- rnorm(n,mean=init.mean,sd=init.sd)^2\n  \n  for(ite in 1:iteration){\n    ##update parameter\n    est.beta <- t((tanh(sqrt(h.ksi)/2)/(2*sqrt(h.ksi)))*x)%*%x+beta*eye(M)\n    est.mean <- solve(est.beta) %*% apply((y-0.5)*x,2,sum)\n    \n    ##update latent variable\n    h.ksi <- diag(x %*% (solve(est.beta)+est.mean%*%t(est.mean)) %*% t(x))\n    \n    ##calculate energy\n    energy <- as.numeric(-(determinant(beta*eye(M),logarithm = T)$modulus-determinant(est.beta,logarithm = T)$modulus)/2-\n      t(est.mean)%*%est.beta%*%est.mean/2+n*log(2)+\n      sum(log(cosh(sqrt(h.ksi)/2))-tanh(sqrt(h.ksi)/2)/(4*sqrt(h.ksi))*h.ksi))\n    \n    print(energy)\n  }\n  return(list(param = est.mean, beta = est.beta, energy=energy))\n}\n\nLVA.mixture.logistic.regression <- function(x,y,K,beta = 0.001, phi=1,\n                                    iteration=100, seed=1,\n                                    init.mean=0, init.sd=1, init.phi=1){\n  set.seed(seed)\n  \n  n <- nrow(x)\n  M <- ncol(x)\n  \n  ##initial setting\n  g.ksi <- matrix(rnorm(n*K,mean=init.mean,sd=init.sd)^2,nrow=n,ncol=K)\n  label.prob <- matrix(0,nrow = n, ncol=K)\n  for(i in 1:n){\n    label.prob[i,] <- rdirichlet(K, phi=init.phi)\n  }\n  \n  est.beta <- array(0, dim=c(M,M,K))\n  est.mean <- matrix(0, nrow=M, ncol=K)\n  est.phi <- numeric(K)\n  \n  for(ite in 1:iteration){\n    ##update parameter\n    est.phi <- apply(label.prob,2,sum)+phi\n    eta.ksi <- -tanh(sqrt(g.ksi)/2)/(4*sqrt(g.ksi))\n    for(k in 1:K){\n      est.beta[,,k] <- t((label.prob[,k]*(-2*eta.ksi[,k]))*x)%*%x + beta*eye(M)\n      est.mean[,k] <- solve(est.beta[,,k])%*%apply(label.prob[,k]*(y-0.5)*x,2,sum)\n    }\n    \n    ##update latent variable\n    prev.g.ksi <- g.ksi\n    for(k in 1:K){\n      g.ksi[,k] <- diag(x %*% (solve(est.beta[,,k])+est.mean[,k]%*%t(est.mean[,k])) %*% t(x))\n    }    \n    \n    ##update label probability\n    h.tau <- rep(1,n) %*% t(digamma(est.phi)-digamma(sum(est.phi)))+\n      ((y-0.5)*x)%*%est.mean-log(2)-log(cosh(sqrt(g.ksi)/2))+\n      eta.ksi*(g.ksi-prev.g.ksi)\n    max.h.tau <- apply(h.tau,1,max)\n    h.tau.dash <- h.tau - max.h.tau%*%t(rep(1,K))\n    label.prob <- exp(h.tau.dash)/(apply(exp(h.tau.dash),1,sum)%*%t(rep(1,K)))\n    \n    ##calculate energy\n    energy <- 0\n    energy <- energy -sum(lgamma(est.phi))+lgamma(sum(est.phi))+K*lgamma(phi)-lgamma(K*phi)\n    for(k in 1:K){\n      energy <- energy + (t(est.mean[,k])%*%est.beta[,,k]%*%est.mean[,k] + as.numeric(determinant(est.beta[,,k])$modulus) - M*log(beta))/2\n    }\n    energy <- energy + sum((eta.ksi*g.ksi+h.tau)*label.prob)\n    energy <- energy + sum(label.prob*log(cosh(sqrt(g.ksi)/2)))\n    energy <- energy - sum(log(apply(exp(h.tau.dash),1,sum))+max.h.tau)\n    # energy <- as.numeric(-(determinant(beta*eye(M),logarithm = T)$modulus-determinant(est.beta,logarithm = T)$modulus)/2-\n    #                        t(est.mean)%*%est.beta%*%est.mean/2+n*log(2)+\n    #                        sum(log(cosh(sqrt(g.ksi)/2))-tanh(sqrt(g.ksi)/2)/(4*sqrt(g.ksi))*g.ksi))\n    # \n    print(energy)\n  }\n  energy <- 0\n  return(list(param=list(ratio = est.phi/sum(est.phi), weight = est.mean), beta = est.beta, energy=energy))\n}\n\n\nLVA.mixture.logistic.regression.debug <- function(x,y,K,beta = 0.001, phi=1,\n                                            iteration=100, seed=1,\n                                            init.mean=0, init.sd=1, init.phi=1){\n  set.seed(seed)\n  \n  n <- nrow(x)\n  M <- ncol(x)\n  \n  ##initial setting\n  g.ksi <- matrix(rnorm(n*K,mean=init.mean,sd=init.sd)^2,nrow=n,ncol=K)\n  latent.prob <- matrix(0,nrow = n, ncol=K)\n  for(i in 1:n){\n    latent.prob[i,] <- rdirichlet(K, phi=init.phi)\n  }\n  \n  est.beta <- array(0, dim=c(M,M,K))\n  est.mean <- matrix(0, nrow=M, ncol=K)\n  est.phi <- numeric(K)\n  \n  for(ite in 1:iteration){\n    ##update parameter\n    est.phi <- apply(latent.prob,2,sum)+phi\n    eta.ksi <- -tanh(sqrt(g.ksi)/2)/(4*sqrt(g.ksi))\n    for(k in 1:K){\n      est.beta[,,k] <- t((latent.prob[,k]*(-2*eta.ksi[,k]))*x)%*%x+beta*eye(M)\n      est.mean[,k] <- solve(est.beta[,,k])%*%apply((latent.prob[,k]*(y-0.5))*x,2,sum)\n    }\n    \n    ##update label probability\n    # h.tau <- rep(1,n) %*% t(digamma(est.phi)-digamma(sum(est.phi)))+\n    #   ((y-0.5)*x)%*%est.mean-log(2*cosh(sqrt(g.ksi)/2))+\n    #   eta.ksi*(g.ksi-prev.g.ksi)\n    h.tau <- rep(1,n) %*% t(digamma(est.phi)-digamma(sum(est.phi)))+\n      ((y-0.5)*x)%*%est.mean-log(2*cosh(sqrt(g.ksi)/2))\n    max.h.tau <- apply(h.tau,1,max)\n    h.tau.dash <- h.tau - max.h.tau%*%t(rep(1,K))\n    latent.prob <- exp(h.tau.dash)/(apply(exp(h.tau.dash),1,sum)%*%t(rep(1,K)))    \n    \n    ##update ksi\n    prev.g.ksi <- g.ksi\n    for(k in 1:K){\n      g.ksi[,k] <- diag(x %*% (solve(est.beta[,,k])+est.mean[,k]%*%t(est.mean[,k])) %*% t(x))\n    }    \n    \n    ##calculate energy\n    energy <- 0\n    energy <- energy -sum(lgamma(est.phi))+lgamma(sum(est.phi))+K*lgamma(phi)-lgamma(K*phi)\n    for(k in 1:K){\n      energy <- energy + (t(est.mean[,k])%*%est.beta[,,k]%*%est.mean[,k] + as.numeric(determinant(est.beta[,,k])$modulus) - M*log(beta))/2\n    }\n    energy <- energy + sum((eta.ksi*g.ksi+h.tau)*latent.prob)\n    energy <- energy + sum(latent.prob*log(cosh(sqrt(g.ksi)/2)))\n    energy <- energy - sum(log(apply(exp(h.tau.dash),1,sum))+max.h.tau)\n    print(energy)\n  }\n  energy <- 0\n  return(list(param=list(ratio = est.phi/sum(est.phi), weight = est.mean), beta = est.beta, energy=energy))\n}\n\neye <- function(M){\n  return(diag(rep(1,M)))\n}\n\nones <- function(n,m){\n  return(matrix(1,nrow=n,ncol=m))\n}\n\nrdirichlet <- function(K,phi){\n  tmp <- rgamma(K,shape=phi)\n  return(tmp/sum(tmp))\n}",
    "created" : 1505621767630.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "748685111",
    "id" : "5F859769",
    "lastKnownWriteTime" : 1506742317,
    "last_content_update" : 1506742317394,
    "path" : "~/research/R/LVA_logistic/logistic.R",
    "project_path" : "logistic.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}